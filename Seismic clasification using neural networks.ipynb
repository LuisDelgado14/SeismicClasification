{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.layers import Input, Conv2D, Dense, Flatten, Dropout\n",
    "from tensorflow.keras.layers import GlobalMaxPooling2D, MaxPooling2D\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn import preprocessing\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name=\"Models/LSTM/Binary/model1_Multicapa_win60_squaredhinge_callback200_monitor-val_accuracy_train2007-2013_validacion2014_testing2015.h5\"#The name of the model that you want to test\n",
    "is_multiclass=False\n",
    "\n",
    "window=60#The window of the model tensor, in this case the tensor is a matrix with shape (60,12)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_dist(X1,X2,Y1,Y2):#This function calculate the euclidian dist between two points\n",
    "  return ((X1-X2)**2+(Y1-Y2)**2)**(1/2)\n",
    "\n",
    "def create_tensor(dataset,look_back):#This function works in pandas Data Frame\n",
    "  dataX, dataY=[],[]\n",
    "  for i in range(look_back,len(dataset)):\n",
    "    matrix=[]\n",
    "    current=dataset.iloc[i]\n",
    "    for j in range(i-look_back,i):\n",
    "      previous=dataset.iloc[j]\n",
    "      dist=calculate_dist(current[\"long\"],previous[\"long\"],current[\"lat\"],previous[\"lat\"])#Euclidian dist \n",
    "      dt=current[\"time\"]-previous[\"time\"]#Time diff\n",
    "      dm=current[\"magn1\"]-previous[\"magn1\"]#Magnitude diff\n",
    "      matrix.append([current[\"lat\"],current[\"long\"],current[\"z\"],current[\"magn1\"],previous[\"lat\"],previous[\"long\"],previous[\"z\"],previous[\"magn1\"],previous[\"Label\"],dist,dt,dm])#Tensor Shape\n",
    "    dataX.append(matrix)\n",
    "    dataY.append(current[\"Label\"])#Label of the cluster\n",
    "  return  np.array(dataX), np.array(dataY)\n",
    "\n",
    "def labeler(df,multiclass=False):\n",
    "    columns=[\"lat\",\"long\",\"z\",\"magn1\",\"time\",\"date_time\",\"cluster\"]\n",
    "    data=df[columns]\n",
    "    df=df.sort_values(by=\"cluster\",ascending=True)\n",
    "    \n",
    "    clusters=list(set(data.cluster.values))\n",
    "    columns.append(\"Label\")\n",
    "    df_out=pd.DataFrame(columns=columns)\n",
    "    for cluster in clusters:\n",
    "        filter_by_cluster=data[data[\"cluster\"]==cluster]\n",
    "        \n",
    "        max_mag=filter_by_cluster.sort_values(by=\"magn1\",ascending=False)\n",
    "        max_mag_index=list(max_mag.index.values)\n",
    "        time=list(max_mag.time.values)\n",
    "        time=time[0]\n",
    "        max_mag_index=max_mag_index[0]#Index of the seismic eventi with the max magnitude in the cluster\n",
    "        \n",
    "        if(multiclass == False):#If you use a binary model the labels needs to be -1 and 1\n",
    "            if(cluster==-1):\n",
    "                label=[]\n",
    "                for i in range(len(filter_by_cluster)):\n",
    "                    label.append(-1)#We consider the noises points like a Mainshock without Aftershock\n",
    "                filter_by_cluster[\"Label\"]=label\n",
    "                \n",
    "            else:\n",
    "                label=[]\n",
    "                for j,row in filter_by_cluster.iterrows():\n",
    "                    if(row.time<time):\n",
    "                        label.append(-1)#Mainshock\n",
    "                    elif(row.time==time):\n",
    "                        label.append(-1)#Mainshock\n",
    "                    elif(row.time>time):\n",
    "                        label.append(1)#Aftershock\n",
    "                filter_by_cluster[\"Label\"]=label\n",
    "                \n",
    "        else:\n",
    "            if(cluster==-1):\n",
    "                label=[]\n",
    "                for i in range(len(filter_by_cluster)):\n",
    "                    label.append(1)#We consider the noises points like a Mainshock without Aftershock\n",
    "                filter_by_cluster[\"Label\"]=label\n",
    "            else:\n",
    "                label=[]\n",
    "                for j,row in filter_by_cluster.iterrows():\n",
    "                    if(row.time<time):\n",
    "                        label.append(0)#Foreshock\n",
    "                    elif(row.time==time):\n",
    "                        label.append(1)#Mainshock\n",
    "                    elif(row.time>time):\n",
    "                        label.append(2)#Aftershock\n",
    "                filter_by_cluster[\"Label\"]=label\n",
    "                filter_by_cluster[\"Label\"]=label\n",
    "                \n",
    "        df_out=pd.concat([df_out,filter_by_cluster])\n",
    "        df_out=df_out.sort_values(by=\"time\")\n",
    "    df=df_out[[\"lat\",\"long\",\"z\",\"magn1\",\"date_time\",\"time\",\"cluster\",\"Label\"]]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def from_dataframe_to_tensor(df_train,df_test,df_validation,window): \n",
    "\n",
    "    #Create Tensor \n",
    "    trainX,trainY=create_tensor(df_train,window)\n",
    "    testX,testY=create_tensor(df_test,window)\n",
    "    valX,valY=create_tensor(df_validation,window)\n",
    "    \n",
    "    \n",
    "    #Normalize the matrix of inputs\n",
    "    shape_tensor_trainX=trainX.shape\n",
    "    trainX=trainX.reshape(trainX.shape[0]*trainX.shape[1], 12)\n",
    "\n",
    "    shape_tensor_valX=valX.shape\n",
    "    valX=valX.reshape(valX.shape[0]*valX.shape[1], 12)\n",
    "\n",
    "    shape_tensor_testX=testX.shape\n",
    "    testX=testX.reshape(testX.shape[0]*testX.shape[1], 12)\n",
    "    \n",
    "    #Aplly the same normalization rules to the train,val and test data\n",
    "    scaler = preprocessing.StandardScaler().fit(trainX)\n",
    "    trainX=scaler.transform(trainX)\n",
    "\n",
    "    testX=scaler.transform(testX)\n",
    "    valX=scaler.transform(valX)\n",
    "    \n",
    "    #Re-reshape to the tensor 3D shape\n",
    "    trainX=trainX.reshape(shape_tensor_trainX)\n",
    "    valX=valX.reshape(shape_tensor_valX)\n",
    "    testX=testX.reshape(shape_tensor_testX)\n",
    "    \n",
    "    print(\"Normalization process successfully completed\")\n",
    "    input_shape = trainX.shape[1:]\n",
    "    return trainX,trainY,testX,testY,valX,valY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          lat    long      z  magn1         time cluster Label\n",
      "0     -31.974 -71.157   55.0    2.2  2557.093631      -1    -1\n",
      "1     -30.682 -71.466   29.8    2.6  2557.106361      -1    -1\n",
      "2     -30.314 -71.481   44.2    3.2  2557.133398      -1    -1\n",
      "3     -28.811 -71.286   75.3    4.1  2557.379895      -1    -1\n",
      "4     -27.144 -71.425   46.8    3.4  2557.613781      -1    -1\n",
      "...       ...     ...    ...    ...          ...     ...   ...\n",
      "35825 -21.160 -68.907  115.0    2.7  5113.430706     519     1\n",
      "35826 -19.738 -69.223   99.4    3.7  5113.449931      -1    -1\n",
      "35827 -21.044 -68.419  178.7    3.8  5113.473206      -1    -1\n",
      "35828 -23.940 -67.447  226.5    3.4  5113.817685     564     1\n",
      "35829 -22.313 -68.658  128.1    3.5  5113.973356      -1    -1\n",
      "\n",
      "[35830 rows x 7 columns]\n",
      "          lat    long      z  magn1         time cluster Label\n",
      "35830 -31.385 -69.557  128.9    3.3  5114.216528      -1    -1\n",
      "35831 -28.617 -71.199   69.8    3.8  5114.242280      -1    -1\n",
      "35832 -30.412 -71.270   37.6    2.6  5114.368588      -1    -1\n",
      "35833 -21.250 -68.355  137.7    3.3  5114.464398     420    -1\n",
      "35834 -27.848 -71.223   69.8    3.4  5114.545324      -1    -1\n",
      "...       ...     ...    ...    ...          ...     ...   ...\n",
      "42548 -31.001 -71.445   57.4    3.5  5478.903287      -1    -1\n",
      "42549 -20.782 -67.980  187.5    4.0  5478.914190      -1    -1\n",
      "42550 -34.002 -72.477   37.8    3.1  5478.923426     619    -1\n",
      "42551 -29.028 -71.495   40.8    2.6  5478.985336     620    -1\n",
      "42552 -27.498 -70.761   41.7    3.3  5478.995000      -1    -1\n",
      "\n",
      "[6723 rows x 7 columns]\n",
      "          lat    long      z  magn1         time cluster Label\n",
      "42553 -33.980 -72.543   30.1    3.1  5479.038553      -1    -1\n",
      "42554 -32.397 -71.510   10.0    3.7  5479.179711      -1    -1\n",
      "42555 -22.121 -68.693  110.9    2.8  5479.679074      -1    -1\n",
      "42556 -22.038 -68.699  114.1    2.8  5479.839259      -1    -1\n",
      "42557 -31.072 -71.347   61.2    4.9  5479.880810      -1    -1\n",
      "...       ...     ...    ...    ...          ...     ...   ...\n",
      "49129 -21.140 -68.557  129.2    2.8  5843.747326      -1    -1\n",
      "49130 -33.903 -72.481   36.7    3.5  5843.791667      -1    -1\n",
      "49131 -24.868 -70.247   45.8    3.5  5843.875706      -1    -1\n",
      "49132 -20.211 -68.955   96.6    3.0  5843.909722      -1    -1\n",
      "49133 -33.834 -71.957   45.1    2.5  5843.965995      -1    -1\n",
      "\n",
      "[6581 rows x 7 columns]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#Preproseciong the dataframe\n",
    "df1 = pd.read_csv(\"Test_2007_2017_Max_Epsilon_10.0_4_15.0_with_DBSCAN_and_K-Means.csv_with_DBSCAN_and_K-Means.csv\",sep=\",\")#Mejor Constitucion 2010\n",
    "df1['date_time'] = pd.to_datetime(df1['date_time'], format='%Y-%m-%d')\n",
    "df1=labeler(df1,is_multiclass)\n",
    "\n",
    "df2 = pd.read_csv(\"Test_2007_2017_Max_Epsilon_10.0_4_25.0_with_DBSCAN_and_K-Means.csv_with_DBSCAN_and_K-Means.csv\",sep=\",\")#Mejor Iquique 2014\n",
    "df2['date_time'] = pd.to_datetime(df2['date_time'], format='%Y-%m-%d')\n",
    "df2=labeler(df2,is_multiclass)\n",
    "\n",
    "df3 = pd.read_csv(\"Test_STDBSCAN_Manual_10.0_10.0_4.0_with_DBSCAN_and_K-Means.csv_with_DBSCAN_and_K-Means.csv\",sep=\",\")#Mejor Coquimbo 2015\n",
    "df3['date_time'] = pd.to_datetime(df3['date_time'], format='%Y-%m-%d')\n",
    "df3=labeler(df3,is_multiclass)\n",
    "\n",
    "\n",
    "df_train=df1[df1[\"date_time\"]<\"01-01-2014\"]#From 2007-07-01 to 2013-12-31\n",
    "df_train=df_train.sort_values(by=\"time\")\n",
    "df_train=df_train.drop(axis=1,columns=[\"date_time\"])\n",
    "print(df_train)\n",
    "\n",
    "\n",
    "df_validation=df2[(df2[\"date_time\"]>=\"01-01-2014\")]#From 2024-01-01\n",
    "df_validation=df_validation[df_validation[\"date_time\"]<\"01-01-2015\"]#To 2024-12-31\n",
    "df_validation=df_validation.sort_values(by=\"time\")\n",
    "df_validation=df_validation.drop(axis=1,columns=[\"date_time\"])\n",
    "print(df_validation)\n",
    "\n",
    "df_test=df3[df3[\"date_time\"]>=\"01-01-2015\"]#From 2015-01-2015\n",
    "df_test=df_test[df_test[\"date_time\"]<\"01-01-2016\"]#To  2015-12-31\n",
    "df_test=df_test.sort_values(by=\"time\")\n",
    "df_test=df_test.drop(axis=1,columns=[\"date_time\"])\n",
    "print(df_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing this could take a few minutes...\n"
     ]
    }
   ],
   "source": [
    "print(\"Processing this could take a few minutes...\")\n",
    "trainX,trainY,testX,testY,valX,valY=from_dataframe_to_tensor(df_train,df_test,df_validation,window)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Loaded window of: 60\"!\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  No replica       0.79      0.98      0.88      4433\n",
      "     Replica       0.92      0.45      0.60      2088\n",
      "\n",
      "    accuracy                           0.81      6521\n",
      "   macro avg       0.85      0.72      0.74      6521\n",
      "weighted avg       0.83      0.81      0.79      6521\n",
      "\n",
      "Confusion Matrix\n",
      "[[4347   86]\n",
      " [1148  940]]\n",
      "Finish ...\n"
     ]
    }
   ],
   "source": [
    "model =  keras.models.load_model(model_name)\n",
    "print(f'Model Loaded window of: {window}\"!')\n",
    "yhat = model.predict(testX, verbose=0)    \n",
    "if(is_multiclass==False):\n",
    "    list_round_values=np.where(yhat>0.5,1,-1)#Round the values greater-than 0.5 to 1\n",
    "    y_true = list(df_test.iloc[window:][\"Label\"].values)\n",
    "    y_pred = list_round_values\n",
    "    confusion_matrix(y_true, y_pred)\n",
    "    target_names = ['No replica', 'Replica']\n",
    "    print(classification_report(y_true, y_pred, target_names=target_names))\n",
    "    print(\"Confusion Matrix\")\n",
    "    print(confusion_matrix(y_true, y_pred, labels=[-1,1]))\n",
    "else:\n",
    "    pred=[]\n",
    "    for foreshock,mainshock,aftershock in yhat:\n",
    "        if(foreshock>mainshock and foreshock >aftershock):\n",
    "            pred.append(0)\n",
    "        elif(mainshock>foreshock and mainshock >aftershock):\n",
    "            pred.append(1)\n",
    "        else:\n",
    "            pred.append(2)\n",
    "    y_true = list(df_test.iloc[window:][\"Label\"].values)\n",
    "    y_pred = list(pred)\n",
    "    confusion_matrix(y_true, y_pred)\n",
    "    target_names = ['Precursor',\"Principal\", 'Replica']\n",
    "    print(classification_report(y_true, y_pred, target_names=target_names))\n",
    "    \n",
    "    print(\"Confusion Matrix\")\n",
    "    print(confusion_matrix(y_true, y_pred, labels=[0,1, 2]))\n",
    "\n",
    "print(\"Finish ...\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
